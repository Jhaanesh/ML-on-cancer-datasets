# -*- coding: utf-8 -*-
"""Advanced_Preprocessing

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12rDj3W9AOA_mLaIuMcJoUR7D7d5EWN_-

**This code is pre processed with KNN for filling missing values, results show that they have very high prediction accuracy with 99% prediction accuracy in XGB** (Previous studies by Islam et al 2020, show 98% accuracy using ANN)
"""

import pandas as pd

from sklearn.impute import KNNImputer

pip install ucimlrepo

from ucimlrepo import fetch_ucirepo

# fetch dataset
breast_cancer_wisconsin_original = fetch_ucirepo(id=15)

# data (as pandas dataframes)
X = breast_cancer_wisconsin_original.data.features
y = breast_cancer_wisconsin_original.data.targets

# metadata
print(breast_cancer_wisconsin_original.metadata)

# variable information
print(breast_cancer_wisconsin_original.variables)

imputer = KNNImputer(n_neighbors=5)

X_imputed = imputer.fit_transform(X)

X_imputed = pd.DataFrame(X_imputed, columns=X.columns)

X_imputed.head()

print("Missing values after imputation:")
print(X_imputed.isnull().sum())

"""Model Training and testing"""

from sklearn.model_selection import train_test_split

a = X_imputed
b = y

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(a, b, test_size=0.2, random_state=42)

from sklearn.preprocessing import StandardScaler

# Scale the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#Random Forests
from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
classifier.fit(X_train, y_train)

from sklearn.metrics import accuracy_score, classification_report

# Evaluate the performance of the model
y_pred = classifier.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print('Accuracy of the model:', accuracy)
print('Classification Report:\n', report)

#SVM
from sklearn.svm import SVC
from sklearn.utils import column_or_1d # Import the missing function

# Train the SVM model
y = column_or_1d(y, warn=True)
model = SVC(kernel='linear', C=1)
model.fit(X_train, y_train)

from sklearn.metrics import accuracy_score, classification_report

# Evaluate the performance of the model
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print('Accuracy:', accuracy)
print('Classification Report:\n', report)

#Logistic Regression
from sklearn.linear_model import LogisticRegression

logreg = LogisticRegression()
logreg.fit(X_train, y_train)
predictions1 = logreg.predict(X_test)

from sklearn.metrics import confusion_matrix, classification_report

print("Confusion Matrix: \n", confusion_matrix(y_test, predictions1))
print('\n')
print(classification_report(y_test, predictions1))

from sklearn.metrics import accuracy_score

logreg_acc = accuracy_score(y_test, predictions1)
print("Accuracy of the Logistic Regression Model is: ", logreg_acc)

#Artifical Neural Networks

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.metrics import confusion_matrix, classification_report

from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

encoder = LabelEncoder()
y = encoder.fit_transform(y)
y

scaler = MinMaxScaler()
X_imputed = scaler.fit_transform(X_imputed)
X_imputed

#splitting

X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.15, shuffle=True, random_state=42)

model = Sequential()
model.add(Dense(16, activation='relu', input_dim=X_train.shape[1]))
model.add(Dense(16, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

history = model.fit(X_train, y_train, epochs=200, validation_split=0.2,callbacks=[tf.keras.callbacks.ReduceLROnPlateau()])

# Evaluate the model on test data
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f"Test Loss: {test_loss}")
print(f"Test Accuracy: {test_accuracy}")

# XG - Boost

from xgboost import XGBClassifier

classifier = XGBClassifier()
classifier.fit(X_train, y_train)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.33, random_state=0)

from sklearn.metrics import confusion_matrix
y_pred = classifier.predict(X_test)
cm = confusion_matrix(y_pred, y_test)
cm

from sklearn.metrics import accuracy_score, classification_report

# Evaluate the performance of the model
y_pred = classifier.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print('Accuracy:', accuracy)
print('Classification Report:\n', report)

